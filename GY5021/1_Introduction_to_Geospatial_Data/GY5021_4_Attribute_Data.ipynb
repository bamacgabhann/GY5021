{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ab0d7e-84ea-433b-bc1b-cf0fdbd6f79b",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_4_Attribute_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_4_Attribute_Data.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f6c6c-9344-4e7a-b64a-579b19c856d0",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/bamacgabhann/GY5021/2024/PD_logo.png\" align=center alt=\"UL Geography logo\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edef23d-f7bf-4012-bbbe-0bce06e5f242",
   "metadata": {
    "id": "j-2xUUAfX0xa"
   },
   "source": [
    "# Attribute Data\n",
    "\n",
    "In the Vector Data notebook, we looked at how we can use coordinates as Points, Lines, and Polygons. This is the fundamental basis for a huge amount of geospatial data.\n",
    "\n",
    "I mentioned through the course of that Notebook some examples of what these could each be used for. \n",
    "\n",
    "Points could represent trees, locations of environmental monitors, bus stops, peaks of mountains - any specific single location.\n",
    "\n",
    "Lines could be roads, cycle lanes, railways, shipping routes, flight paths of birds or aircraft, rivers, fences, hedges - anything which starts in one place and finishes in another.\n",
    "\n",
    "Polygons could be countries, counties, cities, buildings, land parcels, a forest, a lake, a flooded area - anything which covers a discrete area.\n",
    "\n",
    "If you just have the coordinates, how do you know which is which?\n",
    "\n",
    "Fair enough, at a base level, it might be obvious that this polygon is the country of Ireland, and that smaller one is a building; and certainly if you've created the data, you'll probably know what you've created. But usually you'll want to distinguish features from each other, which means you'll need more than just the coordinates.\n",
    "\n",
    "For example, in Point data, you might want the heights or the species of the trees, the latest readings from environmental sensors, the routes served at a bus stop, or the elevation of mountain peaks.\n",
    "\n",
    "For line data, you might want to include the name of a road, whether a cycle lane is shared with pedestrians or not, whether a railway line is for passengers or freight or both, whether a shipping route has car ferries or just freight, the bird species or airline for a flight path, the stream order of a river, the height of a fence or hedge.\n",
    "\n",
    "For polygon data, you might want the name or population of a country, county, or city, the use of a building, the owner or use of a land parcel, the type of trees in a forest, the name of a lake, the date of a flood.\n",
    "\n",
    "This is attribute data - information which is included alongside coordinates. The vast majority of the time when you're using vector data, it will have attributes as well as the coordinates.\n",
    "\n",
    "In order to explain how to work with attribute data, it's useful to get a bit of background on arrays, series, and dataframes. As with vector data, I'll use Python examples to explain the fundamentals, but broadly similar will apply to other geospatial tools, like QGIS and ArcGIS Pro. There will be a little bit of explaining the Python tools in particular though, for those who would like to continue using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a154d71-5f42-4b15-bb96-3a16b805e1ae",
   "metadata": {
    "id": "h1rnt6D5wFMF"
   },
   "source": [
    "## 1. Arrays\n",
    "\n",
    "If we have a lot of variables of the same kind, it would be inefficient to store them all separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98333fa-619e-4512-a149-752587cfe08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5\n",
    "b = 9\n",
    "c = 8\n",
    "d = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b050ba9-fddc-4f69-b442-98c86794663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee1b3f-75ec-4571-a36a-3da419cdf579",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b111c-234b-44c5-89c3-698897e8ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27906d-e51c-47c9-b06d-c9a354779f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce4c01-0f79-4c89-9df5-2da1580936ba",
   "metadata": {},
   "source": [
    "Doing things this way means you need a different name for each variable. Each of these variables is going to be stored in a different chunk of memory. If we want to do some data transformation to all of them, we could do it, but it would be rather awkward and inefficient. Say they're distances in km, and we have to convert them to metres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b409d7f-15b7-46fb-8d68-97df49353002",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a*1000\n",
    "b = b*1000\n",
    "c = c*1000\n",
    "d = d*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ef6c8-8824-4069-937f-ae1991b5b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77aeec-8742-4160-b7e0-bfbc552a2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6e8d7-d110-40e7-b947-154c206a86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede2390-1c56-41f0-b4b3-4db0552d7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7839014-08b4-4c93-9721-cdca4d11dcdf",
   "metadata": {},
   "source": [
    "This isn't just inefficient - it's also slow. That's manageable and not a huge deal when you only have 4 data points, but if you're working with geospatial data, you'll normally have thousands of numbers, not just four or five. Some of the data I work with involves 100,000 datapoints for a day - and I've processed a over a year's worth of data in one go. Something in the region of 50 million data points. If they were all separate variables, that would take a very long time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3c24d-4618-4ef7-b38d-de3d6ae5dd32",
   "metadata": {},
   "source": [
    "## 2. Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b92467-4d9a-409b-b2d8-5fcb9caf342f",
   "metadata": {},
   "source": [
    "Instead, thanks to Python libraries (a library is a collection of modules; a module is a file of Python code containing a set of definitions for objects or kinds of data, and functions for what you can do with them) such as *NumPy* and *Apache Arrow*, we can store a set of related numbers as an *array*. \n",
    "\n",
    "<img src=\"https://github.com/numpy/numpy/blob/main/branding/logo/primary/numpylogo.png?raw=true\" style=\"height:60px\" alt=\"NumPy logo\"/> <img src=\"https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png\" style=\"height:60px\" alt=\"Apache Arrow logo\"/>\n",
    "\n",
    "An *array* is a set of data which is all the same data type; so Python doesn't have to check the data type for each variable individually. It also stores the values in contiguous blocks of memory, so that operations don't involve the computer searching all over the drive to find the next variable - they're all together in one place. \n",
    "\n",
    "Now, a NumPy or Arrow array is just a list of data, it doesn't have anything associated with it. But there are other libraries written to use these arrays for data analysis. One of the most powerful libraries for data processing is *pandas*.\n",
    "\n",
    "<img src=\"https://pandas.pydata.org/static/img/pandas.svg\" style=\"height:60px\" alt=\"Pandas logo\"/>\n",
    "\n",
    "Pandas uses arrays to keep datasets together, and provides tools to analyse that data. To use pandas, first we have to import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb79ec8-83f9-4f53-8dba-ef17b6e24be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d1b50-7118-4d44-a1cf-64d69afafc75",
   "metadata": {},
   "source": [
    "Now let's recreate the data above as a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2fce9-2bdc-403b-9f1a-adfefc159a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([5, 9, 8, 3])\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4fbd6-c42d-4aa8-bfc2-2ba25d7b7c4f",
   "metadata": {},
   "source": [
    "Instead of variables a-d, we now have a series which is _indexed_. Want to convert from km to m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2817a6-f3bc-449f-8f84-acddbf51c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = series*1000\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1446ec-fc16-407c-8063-b561db59433b",
   "metadata": {},
   "source": [
    "We can still refer to and use individual parts of the data, using the index,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc80f7-1c23-477c-b302-143988dcaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "series[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd83c6e-38d2-44d1-b5b9-22fd96c65b7a",
   "metadata": {},
   "source": [
    "Using the tools provided by pandas, we can do a lot of powerful operations on that series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a947a909-ffed-4f89-828d-801d38c2b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc46bf6-3c30-4597-ac19-92ea85ae3b6b",
   "metadata": {},
   "source": [
    "This pandas function, ```series.describe()```, calculates some basic statistics on the dataset. There's a lot more you can do with it as well - change the data type, apply mathematical functions, floating averages, and much much more. You don't need to memorise what you can do with it - just look it up when you need in the [documentation](https://pandas.pydata.org/docs/reference/series.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065e3cb-9ea9-41e2-ac1f-92d12320af71",
   "metadata": {},
   "source": [
    "## 3. Dataframes\n",
    "\n",
    "So, that's nice, but what if we have more than one list of related data? For example, my air pollution research involves measuring particulate pollution of two different sizes, along with pressure, temperature, and humidity. Plus date and time of measurement. That could be 6 separate series.\n",
    "\n",
    "For this, pandas allows multiple arrays to be indexed together as a *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9180f4e-9fc4-4a85-8be6-800e35b80220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Measurement_time\": [\n",
    "            \"2023-11-01 08:00:00\",\n",
    "            \"2023-11-01 08:00:30\",\n",
    "            \"2023-11-01 08:01:00\",\n",
    "            \"2023-11-01 08:01:30\",\n",
    "            \"2023-11-01 08:02:00\",\n",
    "        ],\n",
    "        \"PM2.5\": [3, 4, 6, 2, 3],\n",
    "        \"PM10\": [5, 6, 5, 3, 4],\n",
    "        \"Pressure\": [1012, 1012, 1012, 1013, 1013],\n",
    "        \"Temperature\": [12.5, 12.7, 13.1, 13.2, 13.6],\n",
    "        \"Humidity\": [86, 86, 87, 87, 87],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3b9c04-ee39-4416-a27c-4a46415e9c5c",
   "metadata": {},
   "source": [
    "In the code above, you can see each column header is followed by the data for the relevant column. Pandas knows to interpret this. How to do this with pandas is less important than understanding the overall concept - that we can have multiple arrays associated with a common index. \n",
    "\n",
    "Like with DataSeries, pandas includes numerous functions for working with this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43197e9b-9348-4d58-b6a8-2852f6e650de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9238a-6265-4132-a560-406d972314c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0af2f7-ec08-40a9-94b5-1631a7f20eb0",
   "metadata": {},
   "source": [
    "Here, you can see that the columns contain different types of data. The measurement time one doesn't look right, though - object is usually text, or mixed data. It should be a time format. Well, we can sort that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dfd24-d50c-4844-b82f-ac77b06053ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['Measurement_time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db01a6a-7add-4f58-abeb-6d657216f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8e562-a0d2-4a36-a07f-dd77158f78f7",
   "metadata": {},
   "source": [
    "We can delete the original column now - and even make the timestamp column the index of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9a03e-224e-4cac-a850-74fa5a92e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Measurement_time\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d95c6-5a89-4888-9494-ba1ff0734275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('timestamp')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd397b-6be3-42fe-8d10-b5d77b7b0e5f",
   "metadata": {},
   "source": [
    "There's a lot more we can do with this, and again none of it needs to be memorised - just look up the [documentation](https://pandas.pydata.org/docs/reference/frame.html) whwn you need to. \n",
    "\n",
    "Anyway, I'm getting away from the main point of using both rows and columns to contain data - much like you see in an Excel spreadsheet. \n",
    "\n",
    "One problem though - we're supposed to be talking about geospatial data, and neither the Series nor DataFrame here includes any coordinates. Can pandas do that?\n",
    "\n",
    "Well, no. I mean, you can include columns of coordinates, but to pandas, they'd just be meaningless data. Instead, for working with geospatial data, we have a different library built on top of pandas: GeoPandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a5fb6-f60e-40ce-800b-894fd26031ed",
   "metadata": {},
   "source": [
    "## 4. GeoSeries and GeoDataFrames: GeoPandas\n",
    "\n",
    "GeoPandas adds geospatial properties and functionality to pandas. \n",
    "\n",
    "<img src=\"https://geopandas.org/en/stable/_images/geopandas_logo.png\" style=\"height:60px\" alt=\"GeoPandas logo\"/>\n",
    "\n",
    "A GeoPandas GeoSeries is a subclass of a pandas Series, and a GeoDataFrame is a subclass of a pandas DataFrame. So, anything you can do in pandas to a DataFrame, you can do to a GeoDataFrame -  but GeoPandas adds geospatial information, and a range of geospatial tools.\n",
    "\n",
    "A GeoSeries is a series of Shapely Point, Line, or Polygon coordinates: a geometry series.\n",
    "\n",
    "A GeoDataFrame is a DataFrame with one column being a geometry GeoSeries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010287f-81cd-47b3-a741-cb1e1ab79e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942e85f-21ea-408b-8c7f-dfd50a555b0d",
   "metadata": {},
   "source": [
    "By the way, when I'm using these abbreviations on import - these aren't mine, these are conventions. I'm not able to say for sure how they got to be conventions, but in any case, the vast majority of code you'll find online has\n",
    "\n",
    "```import numpy as np```  \n",
    "```import pandas as pd```  \n",
    "```import geopandas as gpd```  \n",
    "\n",
    "Some are probably just from common use, but there are some which came from the creator. For example, there's a library called seaborn, which is for plotting nice looking graphs. You might think it should be import seaborn as sb or sn, but it's actually\n",
    "\n",
    "```import seaborn as sns```\n",
    "\n",
    "because that's the initials of the character Samuel Normal Seaborn from The West Wing. \n",
    "\n",
    "Python people are just like this sometimes, I don't know what to tell you. Also, I might mention here that Python is not named after the snake, even if that's the interpretation implied by the existence of Anaconda and similar Python tools. It's named after Monty Python, and you will very often see python tutorials using Monty Python references in their example code, e.g. ```spam``` for variable names. If you don't like it, well, you can always use R.\n",
    "\n",
    "Anyway, let's recreate the dataframe above, but this time, with added coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e79a0-2fe9-4e44-b2bc-5d0fdc27c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"Meas_time\": [\n",
    "            \"2023-11-01 08:00:00\",\n",
    "            \"2023-11-01 08:00:30\",\n",
    "            \"2023-11-01 08:01:00\",\n",
    "            \"2023-11-01 08:01:30\",\n",
    "            \"2023-11-01 08:02:00\",\n",
    "        ],\n",
    "        \"PM2.5\": [3, 4, 6, 2, 3],\n",
    "        \"PM10\": [5, 6, 5, 3, 4],\n",
    "        \"Pressure\": [1012, 1012, 1012, 1013, 1013],\n",
    "        \"Temperature\": [12, 12, 13, 13, 13],\n",
    "        \"Humidity\": [86, 86, 87, 87, 87],\n",
    "        \"geometry\": [Point(555173, 654321), Point(555173, 654321), Point(555173, 654321), Point(555173, 654321), Point(555173, 654321)],\n",
    "    }\n",
    ")\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb602a-268f-4f80-9d74-041812dc458e",
   "metadata": {},
   "source": [
    "Now, we're *really* getting somewhere.\n",
    "\n",
    "This can be plotted on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd245eb2-1cae-4ff8-98b5-98f1c357339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a792b60-b60e-4a56-8dbf-1918c041adfb",
   "metadata": {},
   "source": [
    "Okay, that's not the most useful plot everywhere, because all the readings were taken (or, in this case, made up) at the same point. But we could equally plot points in different locations, or lines, or polygons. Let's go back to our examples from the Vector Data Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a002f-4b3c-4256-a35c-4ad08a1cc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = gpd.GeoDataFrame({\n",
    "    \"geometry\": [Point(1, 7), Point(6, 2), Point(8, 8), Point(5, 9)],\n",
    "    \"species\": [\"Oak\", \"Oak\", \"Scot's Pine\", \"Birch\"] \n",
    "})\n",
    "\n",
    "trees.plot(\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf793d17-98d1-4a4e-86f1-9b7e544f78fe",
   "metadata": {},
   "source": [
    "Notice the two points which are the same colour - because they're both labelled as oak trees in the species column, which we specified to use in the plot. So, this is a map of trees, distinguished by type. \n",
    "\n",
    "We can do similar with lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32823a7-c544-489e-88bf-0ca78a3eb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import LineString, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ef94c-2b6d-4276-8291-8c41145a740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = gpd.GeoDataFrame({\n",
    "    \"geometry\": [LineString([(7, 7), (5, 9)]), LineString([(6, 2), (4, 5), (7, 7)]), LineString([(4, 5), (1, 7)]), LineString([(7, 7), (8, 8)])],\n",
    "    \"Stream Order\": [1, 2, 1, 1]\n",
    "})\n",
    "rivers.plot(\"Stream Order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b086b3e-2f2c-4f54-bb54-8e61753cd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "LandUse = gpd.GeoDataFrame({\n",
    "    \"geometry\": [Polygon([(1, 7), (6, 2), (8, 8), (5, 9)]), Polygon([(12, 14), (16, 17), (15, 14), (11, 10)])],\n",
    "    \"Land Use\": [\"Forest\", \"Rock\"]\n",
    "})\n",
    "LandUse.plot(\"Land Use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7bc6b-6750-4074-a9cf-3936882e5067",
   "metadata": {},
   "source": [
    "Again, this is just the very simplest case using Python, but the principle holds across *any* geospatial tools. You can have point, line, or polygon coordinates associated with data about what's at those coordinates, and plot that data on maps. \n",
    "\n",
    "There is one more fundamental point that we need to cover before looking at what we can do with geospatial vector data. \n",
    "\n",
    "In the examples from the Vector Data notebooks, which I reused here, you may have noticed that all the coordinates are just simple integers. These obviously don't look like real coordinates.\n",
    "\n",
    "In the air pollution data example above, you might have noticed the coordinates are a bit different - each has two six-figure numbers. That looks a bit more like real coordinates, perhaps, but it's certainly not latitude and longitude numbers. What type of coordinates are they? \n",
    "\n",
    "For the answer to this, and other questions, we have to go to our next Notebook, Coordinate Reference Systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23864c-f37b-4a15-9a76-14505f4b3db0",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Week 1 Notebooks: \n",
    "\n",
    "1. Geospatial Software and Programming Languages <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_1_Geospatial_Software_and_Programming_Languages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_1_Geospatial_Software_and_Programming_Languages.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "2. Data Types <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_2_Data_Types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_2_Data_Types.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "3. Vector Data <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_3_Vector_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_3_Vector_Data.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "4. Attribute Data <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_4_Attribute_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_4_Attribute_Data.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "5. Coordinate Reference Systems <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_5_Coordinate_Reference_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_5_Coordinate_Reference_Systems.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "6. Geospatial Data Files <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_6_Geospatial_Data_Files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_6_Geospatial_Data_Files.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "7. Vector Geoprocessing <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_7_Vector_Geoprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_7_Vector_Geoprocessing.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "Additional:\n",
    "\n",
    "- The Python Language <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_The_Python_Language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_The_Python_Language.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>\n",
    "\n",
    "- Getting Started Seriously With Python <a href=\"https://colab.research.google.com/github/bamacgabhann/GY5021/blob/2024/GY5021/1_Introduction_to_Geospatial_Data/GY5021_Getting_Started_Seriously_With_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>     <a href=\"https://mybinder.org/v2/gh/bamacgabhann/GY5021/9a706c8973d5bde0e50593ecc94941b0426f24a6?urlpath=lab%2Ftree%2FGY5021%2F1_Introduction_to_Geospatial_Data%2FGY5021_Getting_Started_Seriously_With_Python.ipynb\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\" /></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GY5021",
   "language": "python",
   "name": "gy5021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
